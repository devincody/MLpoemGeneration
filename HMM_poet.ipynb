{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "import pdb\n",
    "%matplotlib inline\n",
    "\n",
    "from HMM_sonnet import HiddenMarkovModel\n",
    "from HMM_sonnet_helper import (\n",
    "    #text_to_wordcloud,\n",
    "    #states_to_wordclouds,\n",
    "    parse_observations,\n",
    "    sample_sentence,\n",
    "    write_naive_line,\n",
    "    visualize_sparsities,\n",
    "    animate_emission\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Shakespearean and Spenser sonnets, and rhyme dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(keys, values):\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = open(\"data/shakespeare.txt\",'r').readlines()\n",
    "load_syllables = open(\"data/Syllable_dictionary.txt\",'r').readlines()\n",
    "#load_syllables = open(\"Syllable_dictionary.txt\",'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = []\n",
    "for i in range(len(load_data)):\n",
    "    if load_data[i] != \"\\n\":\n",
    "        shakespeare.append(load_data[i][:-1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_shakespeare = []\n",
    "for i in range(len(shakespeare)):\n",
    "    line = []\n",
    "    for j in range(len(shakespeare[i])):\n",
    "        if shakespeare[i][j] != '':\n",
    "            word = ''\n",
    "            punc = ''\n",
    "            if shakespeare[i][j][0] in \",.;:!'()?\":\n",
    "                line.append(shakespeare[i][j][0])\n",
    "                if shakespeare[i][j][-1] in \",.;:!'()?\":\n",
    "                    if shakespeare[i][j][-2] in \",.;:!’'()?\":\n",
    "                        line.append(shakespeare[i][j][1:-2])\n",
    "                        line.append(shakespeare[i][j][-2])\n",
    "                        line.append(shakespeare[i][j][-1])\n",
    "                    else:\n",
    "                        line.append(shakespeare[i][j][1:-1])\n",
    "                        line.append(shakespeare[i][j][-1])\n",
    "                else:\n",
    "                    line.append(shakespeare[i][j][1:])\n",
    "            elif shakespeare[i][j][-1] in \",.;:!'’()?\" and shakespeare[i][j][0] not in \",.;:!'()?\":\n",
    "                if shakespeare[i][j][-2] in \",.;:!’'()?\":\n",
    "                    line.append(shakespeare[i][j][:-2])\n",
    "                    line.append(shakespeare[i][j][-2])\n",
    "                    line.append(shakespeare[i][j][-1])\n",
    "                else:\n",
    "                    line.append(shakespeare[i][j][:-1])\n",
    "                    line.append(shakespeare[i][j][-1])\n",
    "\n",
    "            else:\n",
    "                    line.append(shakespeare[i][j])\n",
    "    processed_shakespeare.append(line)\n",
    "\n",
    "shakespeare_lines = []\n",
    "for line in processed_shakespeare:\n",
    "    if len(line) > 1:\n",
    "        shakespeare_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_notend = []\n",
    "syllables_end = []\n",
    "for i in range(len(load_syllables)):\n",
    "    if load_syllables[i] != \"\\n\":\n",
    "        line = load_syllables[i][:-1].split(' ')\n",
    "        if len(line) == 3:\n",
    "            if line[1][0] == 'E':\n",
    "                syllables_end.append([line[0],int(line[1][1:])])\n",
    "                syllables_notend.append([line[0],[int(line[2]),int(line[2])]])\n",
    "            else:\n",
    "                syllables_notend.append([line[0],[int(line[2]),int(line[2])]])\n",
    "        else:\n",
    "            syllables_notend.append([line[0],[int(line[1]),int(line[1])]])\n",
    "#syllables_notend.append([\"'\",[0,0]])\n",
    "syllables_end_keys = np.array(syllables_end)[:,0]\n",
    "syllables_end_values = np.array(syllables_end)[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_end_dict = create_dict(syllables_end_keys,syllables_end_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_notend_keys = []\n",
    "syllables_notend_values = []\n",
    "for i in range(len(syllables_notend)):\n",
    "    syllables_notend_keys.append(syllables_notend[i][0])\n",
    "    syllables_notend_values.append(syllables_notend[i][1])\n",
    "syllables_notend_keys[-1] = \"'\"\n",
    "syllables_notend_values[-1] = [0,0]\n",
    "syllables_notend_keys = np.array(syllables_notend_keys)\n",
    "syllables_notend_values = np.array(syllables_notend_values).astype(int)\n",
    "syllables_notend_dict = create_dict(syllables_notend_keys,syllables_notend_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtonumber_dict = create_dict(syllables_notend_keys,range(len(syllables_notend_keys)))\n",
    "numbertoword_dict = create_dict(range(len(syllables_notend_keys)),syllables_notend_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_lines_token = []\n",
    "for i in range(len(shakespeare_lines)):\n",
    "    line = []\n",
    "    for word in shakespeare_lines[i]:\n",
    "        line.append(wordtonumber_dict[word.lower()])\n",
    "    shakespeare_lines_token.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yours',\n",
       " 'youth',\n",
       " \"youth's\",\n",
       " 'youthful',\n",
       " 'zealous',\n",
       " ',',\n",
       " '.',\n",
       " ';',\n",
       " ':',\n",
       " '!',\n",
       " '(',\n",
       " ')',\n",
       " '?',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[numbertoword_dict[i] for i in range(3200,3214)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hidden Markov Models on each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class HiddenMarkovModel:\n",
    "    '''\n",
    "    Class implementation of Hidden Markov Models.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, A, O):\n",
    "        '''\n",
    "        Initializes an HMM. Assumes the following:\n",
    "            - States and observations are integers starting from 0. \n",
    "            - There is a start state (see notes on A_start below). There\n",
    "              is no integer associated with the start state, only\n",
    "              probabilities in the vector A_start.\n",
    "            - There is no end state. \n",
    "\n",
    "        Arguments:\n",
    "            A:          Transition matrix with dimensions L x L.\n",
    "                        The (i, j)^th element is the probability of\n",
    "                        transitioning from state i to state j. Note that\n",
    "                        this does not include the starting probabilities.\n",
    "\n",
    "            O:          Observation matrix with dimensions L x D.\n",
    "                        The (i, j)^th element is the probability of\n",
    "                        emitting observation j given state i.\n",
    "\n",
    "        Parameters:\n",
    "            L:          Number of states.\n",
    "\n",
    "            D:          Number of observations.\n",
    "            \n",
    "            A:          The transition matrix.\n",
    "            \n",
    "            O:          The observation matrix.\n",
    "            \n",
    "            A_start:    Starting transition probabilities. The i^th element\n",
    "                        is the probability of transitioning from the start\n",
    "                        state to state i. For simplicity, we assume that\n",
    "                        this distribution is uniform.\n",
    "        '''\n",
    "\n",
    "        self.L = len(A)\n",
    "        self.D = len(O[0])\n",
    "        self.A = A\n",
    "        self.O = O\n",
    "        self.A_start = [1. / self.L for _ in range(self.L)]\n",
    "\n",
    "\n",
    "    def viterbi(self, x):\n",
    "        '''\n",
    "        Uses the Viterbi algorithm to find the max probability state \n",
    "        sequence corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            max_seq:    Output sequence corresponding to x with the highest\n",
    "                        probability.\n",
    "        '''\n",
    "\n",
    "        M = len(x)      # Length of sequence.\n",
    "\n",
    "        # The (i, j)^th elements of probs and seqs are the max probability\n",
    "        # of the prefix of length i ending in state j and the prefix\n",
    "        # that gives this probability, respectively.\n",
    "        #\n",
    "        # For instance, probs[1][0] is the probability of the prefix of\n",
    "        # length 1 ending in state 0.\n",
    "        probs = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "        seqs = [['' for _ in range(self.L)] for _ in range(M + 1)]\n",
    "\n",
    "        # Calculate initial prefixes and probabilities.\n",
    "        for curr in range(self.L):\n",
    "            probs[1][curr] = self.A_start[curr] * self.O[curr][x[0]]\n",
    "            seqs[1][curr] = str(curr)\n",
    "\n",
    "        # Calculate best prefixes and probabilities throughout sequence.\n",
    "        for t in range(2, M + 1):\n",
    "            # Iterate over all possible current states.\n",
    "            for curr in range(self.L):\n",
    "                max_prob = float(\"-inf\")\n",
    "                max_prefix = ''\n",
    "\n",
    "                # Iterate over all possible previous states to find one\n",
    "                # that would maximize the probability of the current state.\n",
    "                for prev in range(self.L):\n",
    "                    curr_prob = probs[t - 1][prev] \\\n",
    "                                * self.A[prev][curr] \\\n",
    "                                * self.O[curr][x[t - 1]]\n",
    "\n",
    "                    # Continually update max probability and prefix.\n",
    "                    if curr_prob >= max_prob:\n",
    "                        max_prob = curr_prob\n",
    "                        max_prefix = seqs[t - 1][prev]\n",
    "\n",
    "                # Store the max probability and prefix.\n",
    "                probs[t][curr] = max_prob\n",
    "                seqs[t][curr] = max_prefix + str(curr)\n",
    "\n",
    "        # Find the index of the max probability of a sequence ending in x^M\n",
    "        # and the corresponding output sequence.\n",
    "        max_i = max(enumerate(probs[-1]), key=lambda x: x[1])[0]\n",
    "        max_seq = seqs[-1][max_i]\n",
    "\n",
    "        return max_seq\n",
    "\n",
    "\n",
    "    def forward(self, x, normalize=False):\n",
    "        '''\n",
    "        Uses the forward algorithm to calculate the alpha probability\n",
    "        vectors corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "            normalize:  Whether to normalize each set of alpha_j(i) vectors\n",
    "                        at each i. This is useful to avoid underflow in\n",
    "                        unsupervised learning.\n",
    "\n",
    "        Returns:\n",
    "            alphas:     Vector of alphas.\n",
    "\n",
    "                        The (i, j)^th element of alphas is alpha_j(i),\n",
    "                        i.e. the probability of observing prefix x^1:i\n",
    "                        and state y^i = j.\n",
    "\n",
    "                        e.g. alphas[1][0] corresponds to the probability\n",
    "                        of observing x^1:1, i.e. the first observation,\n",
    "                        given that y^1 = 0, i.e. the first state is 0.\n",
    "        '''\n",
    "\n",
    "        M = len(x)      # Length of sequence.\n",
    "        alphas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "\n",
    "        # Note that alpha_j(0) is already correct for all j's.\n",
    "        # Calculate alpha_j(1) for all j's.\n",
    "        for curr in range(self.L):\n",
    "            alphas[1][curr] = self.A_start[curr] * self.O[curr][x[0]]\n",
    "\n",
    "        # Calculate alphas throughout sequence.\n",
    "        for t in range(1, M):\n",
    "            # Iterate over all possible current states.\n",
    "            for curr in range(self.L):\n",
    "                prob = 0\n",
    "\n",
    "                # Iterate over all possible previous states to accumulate\n",
    "                # the probabilities of all paths from the start state to\n",
    "                # the current state.\n",
    "                for prev in range(self.L):\n",
    "                    prob += alphas[t][prev] \\\n",
    "                            * self.A[prev][curr] \\\n",
    "                            * self.O[curr][x[t]]\n",
    "\n",
    "                # Store the accumulated probability.\n",
    "                alphas[t + 1][curr] = prob\n",
    "\n",
    "            if normalize:\n",
    "                norm = sum(alphas[t + 1])\n",
    "                for curr in range(self.L):\n",
    "                    alphas[t + 1][curr] /= norm\n",
    "\n",
    "        return alphas\n",
    "\n",
    "\n",
    "    def backward(self, x, normalize=False):\n",
    "        '''\n",
    "        Uses the backward algorithm to calculate the beta probability\n",
    "        vectors corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "            normalize:  Whether to normalize each set of alpha_j(i) vectors\n",
    "                        at each i. This is useful to avoid underflow in\n",
    "                        unsupervised learning.\n",
    "\n",
    "        Returns:\n",
    "            betas:      Vector of betas.\n",
    "\n",
    "                        The (i, j)^th element of betas is beta_j(i), i.e.\n",
    "                        the probability of observing prefix x^(i+1):M and\n",
    "                        state y^i = j.\n",
    "\n",
    "                        e.g. betas[M][0] corresponds to the probability\n",
    "                        of observing x^M+1:M, i.e. no observations,\n",
    "                        given that y^M = 0, i.e. the last state is 0.\n",
    "        '''\n",
    "\n",
    "        M = len(x)      # Length of sequence.\n",
    "        betas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "\n",
    "        # Initialize initial betas.\n",
    "        for curr in range(self.L):\n",
    "            betas[-1][curr] = 1\n",
    "\n",
    "        # Calculate betas throughout sequence.\n",
    "        for t in range(-1, -M - 1, -1):\n",
    "            # Iterate over all possible current states.\n",
    "            for curr in range(self.L):\n",
    "                prob = 0\n",
    "\n",
    "                # Iterate over all possible next states to accumulate\n",
    "                # the probabilities of all paths from the end state to\n",
    "                # the current state.\n",
    "                for nxt in range(self.L):\n",
    "                    if t == -M:\n",
    "                        prob += betas[t][nxt] \\\n",
    "                                * self.A_start[nxt] \\\n",
    "                                * self.O[nxt][x[t]]\n",
    "\n",
    "                    else:\n",
    "                        prob += betas[t][nxt] \\\n",
    "                                * self.A[curr][nxt] \\\n",
    "                                * self.O[nxt][x[t]]\n",
    "\n",
    "                # Store the accumulated probability.\n",
    "                betas[t - 1][curr] = prob\n",
    "\n",
    "            if normalize:\n",
    "                norm = sum(betas[t - 1])\n",
    "                for curr in range(self.L):\n",
    "                    betas[t - 1][curr] /= norm\n",
    "\n",
    "        return betas\n",
    "\n",
    "\n",
    "    def supervised_learning(self, X, Y):\n",
    "        '''\n",
    "        Trains the HMM using the Maximum Likelihood closed form solutions\n",
    "        for the transition and observation matrices on a labeled\n",
    "        datset (X, Y). Note that this method does not return anything, but\n",
    "        instead updates the attributes of the HMM object.\n",
    "\n",
    "        Arguments:\n",
    "            X:          A dataset consisting of input sequences in the form\n",
    "                        of lists of variable length, consisting of integers \n",
    "                        ranging from 0 to D - 1. In other words, a list of\n",
    "                        lists.\n",
    "\n",
    "            Y:          A dataset consisting of state sequences in the form\n",
    "                        of lists of variable length, consisting of integers \n",
    "                        ranging from 0 to L - 1. In other words, a list of\n",
    "                        lists.\n",
    "\n",
    "                        Note that the elements in X line up with those in Y.\n",
    "        '''\n",
    "\n",
    "        # Calculate each element of A using the M-step formulas.\n",
    "        for curr in range(self.L):\n",
    "            for nxt in range(self.L):\n",
    "                num = 0.\n",
    "                den = 0.\n",
    "\n",
    "                for i in range(len(X)):\n",
    "                    x = X[i]\n",
    "                    y = Y[i]\n",
    "                    M = len(x)\n",
    "        \n",
    "                    num += len([1 for i in range(M - 1) \\\n",
    "                                if y[i] == curr and y[i + 1] == nxt])\n",
    "                    den += len([1 for i in range(M - 1) if y[i] == curr])\n",
    "\n",
    "                self.A[curr][nxt] = num / den\n",
    "\n",
    "        # Calculate each element of O using the M-step formulas.\n",
    "        for curr in range(self.L):\n",
    "            for xt in range(self.D):\n",
    "                num = 0.\n",
    "                den = 0.\n",
    "\n",
    "                for i in range(len(X)):\n",
    "                    x = X[i]\n",
    "                    y = Y[i]\n",
    "                    M = len(x)\n",
    "        \n",
    "                    num += len([1 for i in range(M) \\\n",
    "                                if y[i] == curr and x[i] == xt])\n",
    "                    den += len([1 for i in range(M) if y[i] == curr])\n",
    "\n",
    "                self.O[curr][xt] = num / den\n",
    "\n",
    "\n",
    "    def unsupervised_learning(self, X, N_iters):\n",
    "        '''\n",
    "        Trains the HMM using the Baum-Welch algorithm on an unlabeled\n",
    "        datset X. Note that this method does not return anything, but\n",
    "        instead updates the attributes of the HMM object.\n",
    "\n",
    "        Arguments:\n",
    "            X:          A dataset consisting of input sequences in the form\n",
    "                        of lists of length M, consisting of integers ranging\n",
    "                        from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "            N_iters:    The number of iterations to train on.\n",
    "        '''\n",
    "\n",
    "        # Note that a comment starting with 'E' refers to the fact that\n",
    "        # the code under the comment is part of the E-step.\n",
    "\n",
    "        # Similarly, a comment starting with 'M' refers to the fact that\n",
    "        # the code under the comment is part of the M-step.\n",
    "\n",
    "        for iteration in range(1, N_iters + 1):\n",
    "            if iteration % 10 == 0:\n",
    "                print(\"Iteration: \" + str(iteration))\n",
    "\n",
    "            # Numerator and denominator for the update terms of A and O.\n",
    "            A_num = [[0. for i in range(self.L)] for j in range(self.L)]\n",
    "            O_num = [[0. for i in range(self.D)] for j in range(self.L)]\n",
    "            A_den = [0. for i in range(self.L)]\n",
    "            O_den = [0. for i in range(self.L)]\n",
    "\n",
    "            # For each input sequence:\n",
    "            for x in X:\n",
    "                M = len(x)\n",
    "                # Compute the alpha and beta probability vectors.\n",
    "                alphas = self.forward(x, normalize=True)\n",
    "                betas = self.backward(x, normalize=True)\n",
    "\n",
    "                # E: Update the expected observation probabilities for a\n",
    "                # given (x, y).\n",
    "                # The i^th index is P(y^t = i, x).\n",
    "                for t in range(1, M + 1):\n",
    "                    P_curr = [0. for _ in range(self.L)]\n",
    "                    \n",
    "                    for curr in range(self.L):\n",
    "                        P_curr[curr] = alphas[t][curr] * betas[t][curr]\n",
    "\n",
    "                    # Normalize the probabilities.\n",
    "                    norm = sum(P_curr)\n",
    "                    for curr in range(len(P_curr)):\n",
    "                        P_curr[curr] /= norm\n",
    "\n",
    "                    for curr in range(self.L):\n",
    "                        if t != M:\n",
    "                            A_den[curr] += P_curr[curr]\n",
    "                        O_den[curr] += P_curr[curr]\n",
    "                        O_num[curr][x[t - 1]] += P_curr[curr]\n",
    "\n",
    "                # E: Update the expectedP(y^j = a, y^j+1 = b, x) for given (x, y)\n",
    "                for t in range(1, M):\n",
    "                    P_curr_nxt = [[0. for _ in range(self.L)] for _ in range(self.L)]\n",
    "\n",
    "                    for curr in range(self.L):\n",
    "                        for nxt in range(self.L):\n",
    "                            P_curr_nxt[curr][nxt] = alphas[t][curr] \\\n",
    "                                                    * self.A[curr][nxt] \\\n",
    "                                                    * self.O[nxt][x[t]] \\\n",
    "                                                    * betas[t + 1][nxt]\n",
    "\n",
    "                    # Normalize:\n",
    "                    norm = 0\n",
    "                    for lst in P_curr_nxt:\n",
    "                        norm += sum(lst)\n",
    "                    for curr in range(self.L):\n",
    "                        for nxt in range(self.L):\n",
    "                            P_curr_nxt[curr][nxt] /= norm\n",
    "\n",
    "                    # Update A_num\n",
    "                    for curr in range(self.L):\n",
    "                        for nxt in range(self.L):\n",
    "                            A_num[curr][nxt] += P_curr_nxt[curr][nxt]\n",
    "\n",
    "            for curr in range(self.L):\n",
    "                for nxt in range(self.L):\n",
    "                    self.A[curr][nxt] = A_num[curr][nxt] / A_den[curr]\n",
    "\n",
    "            for curr in range(self.L):\n",
    "                for xt in range(self.D):\n",
    "                    self.O[curr][xt] = O_num[curr][xt] / O_den[curr]\n",
    "\n",
    "    def generate_emission(self, M):\n",
    "        '''\n",
    "        Generates an emission of length M, assuming that the starting state\n",
    "        is chosen uniformly at random. \n",
    "\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "\n",
    "        emission = []\n",
    "        state = random.choice(range(self.L))\n",
    "        states = []\n",
    "\n",
    "        for t in range(M):\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "\n",
    "            # Sample next observation.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_obs = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.O[state][next_obs]\n",
    "                next_obs += 1\n",
    "\n",
    "            next_obs -= 1\n",
    "            emission.append(next_obs)\n",
    "\n",
    "            # Sample next state.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_state = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.A[state][next_state]\n",
    "                next_state += 1\n",
    "\n",
    "            next_state -= 1\n",
    "            state = next_state\n",
    "\n",
    "        return emission, states\n",
    "    \n",
    "    def naive_line(self, syl_dic, end_dic, number_to_word): #Think of how to add syllable dictionary.\n",
    "        '''\n",
    "        Generates a sonnet line of ten syllables, without rhyme or meter\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "        emission = []\n",
    "        state = random.choice(range(self.L))\n",
    "        states = []\n",
    "        n_syllables = 0\n",
    "\n",
    "        while n_syllables < 10:\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "            \n",
    "            #IMPORTANT: create a 'try' structure for n_syllables.\n",
    "            \n",
    "            # Sample next observation.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_obs = 0 \n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.O[state][next_obs]\n",
    "                next_obs += 1\n",
    "\n",
    "            next_obs -= 1                 \n",
    "            \n",
    "            #Obtain number of syllables for this word choice.\n",
    "            word_next_obs = number_to_word[next_obs]\n",
    "            new_syllable = random.choice(syl_dic[word_next_obs])\n",
    "            end_syllable = 0\n",
    "            \n",
    "            #Check if selected word is an end-syllable case.\n",
    "            if next_obs in end_dic.keys():\n",
    "                end_syllable = random.choice(end_dic[word_next_obs])\n",
    "            \n",
    "            if n_syllables + new_syllable > 10 or n_syllables + end_syllable > 10:\n",
    "                pass\n",
    "            else:\n",
    "                emission.append(next_obs)\n",
    "\n",
    "                # Sample next state.\n",
    "                rand_var = random.uniform(0, 1)\n",
    "                next_state = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= self.A[state][next_state]\n",
    "                    next_state += 1\n",
    "            \n",
    "                #Create end condition, n_syllables == 10.\n",
    "                if n_syllables + new_syllable == 10 or n_syllables + end_syllable == 10:\n",
    "                    pass\n",
    "                else:\n",
    "                    next_state -= 1\n",
    "                    state = next_state\n",
    "                \n",
    "                n_syllables += new_syllable\n",
    "        return emission, states\n",
    "        \n",
    "    def haiku_line(self, syl_dic, end_dic, number_to_word,num_syllables): #Think of how to add syllable dictionary.\n",
    "        '''\n",
    "        Generates a sonnet line of ten syllables, without rhyme or meter\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "        emission = []\n",
    "        state = random.choice(range(self.L))\n",
    "        states = []\n",
    "        n_syllables = 0\n",
    "\n",
    "        while n_syllables < num_syllables:\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "            \n",
    "            #IMPORTANT: create a 'try' structure for n_syllables.\n",
    "            \n",
    "            # Sample next observation.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_obs = 0 \n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.O[state][next_obs]\n",
    "                next_obs += 1\n",
    "\n",
    "            next_obs -= 1                 \n",
    "            \n",
    "            #Obtain number of syllables for this word choice.\n",
    "            word_next_obs = number_to_word[next_obs]\n",
    "            new_syllable = random.choice(syl_dic[word_next_obs])\n",
    "            end_syllable = 0\n",
    "            \n",
    "            #Check if selected word is an end-syllable case.\n",
    "            if next_obs in end_dic.keys():\n",
    "                end_syllable = random.choice(end_dic[word_next_obs])\n",
    "            \n",
    "            if n_syllables + new_syllable > num_syllables or n_syllables + end_syllable > num_syllables:\n",
    "                pass\n",
    "            else:\n",
    "                emission.append(next_obs)\n",
    "\n",
    "                # Sample next state.\n",
    "                rand_var = random.uniform(0, 1)\n",
    "                next_state = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= self.A[state][next_state]\n",
    "                    next_state += 1\n",
    "            \n",
    "                #Create end condition, n_syllables == 10.\n",
    "                if n_syllables + new_syllable == num_syllables or n_syllables + end_syllable == num_syllables:\n",
    "                    pass\n",
    "                else:\n",
    "                    next_state -= 1\n",
    "                    state = next_state\n",
    "                \n",
    "                n_syllables += new_syllable\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #Treat edge case of end syllables.\n",
    "        if emission[-1] in end_dic.keys(): #FIX FIX FIX\n",
    "            #FIX: Missing some while loop to keep trying words.\n",
    "            \n",
    "            n_syllables -= new_syllable\n",
    "            emission = emission[:-1]\n",
    "            \n",
    "            while n_syllables < 10: #Do we need this?\n",
    "            \n",
    "                #Draw an end word.\n",
    "                rand_var = random.uniform(0, 1)\n",
    "                next_obs = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= self.O[state][next_obs]\n",
    "                    next_obs += 1\n",
    "\n",
    "                next_obs -= 1   \n",
    "            \n",
    "                #Check whether this observation has an end-specific syllable count.\n",
    "                if next_obs in end_dic: #FIX FIX FIX\n",
    "                    if n_syllables + end_dic[next_obs] != 10:\n",
    "                        pass\n",
    "                    else:\n",
    "                        emission.append(next_obs)\n",
    "\n",
    "                        # Sample next state.\n",
    "                        rand_var = random.uniform(0, 1)\n",
    "                        next_state = 0\n",
    "\n",
    "                        while rand_var > 0:\n",
    "                            rand_var -= self.A[state][next_state]\n",
    "                            next_state += 1\n",
    "            \n",
    "                        #Create end condition, n_syllables == 10. DO WE NEED THIS?\n",
    "                        if n_syllables + end_dic[next_obs] == 10:\n",
    "                            pass\n",
    "                        else:\n",
    "                            next_state -= 1\n",
    "                            state = next_state\n",
    "                        \n",
    "                \n",
    "                        n_syllables += end_dic[next_obs]\n",
    "                else: #Case where the word is not in the end-syllable dictionary.\n",
    "                    if n_syllables + syl_dic[next_obs] != 10:\n",
    "                        pass\n",
    "                    else:\n",
    "                        emission.append(next_obs)\n",
    "\n",
    "                        # Sample next state.\n",
    "                        rand_var = random.uniform(0, 1)\n",
    "                        next_state = 0\n",
    "\n",
    "                        while rand_var > 0:\n",
    "                            rand_var -= self.A[state][next_state]\n",
    "                            next_state += 1\n",
    "            \n",
    "                        #Create end condition, n_syllables == 10. DO WE NEED THIS?\n",
    "                        if n_syllables + syl_dic[next_obs] == 10:\n",
    "                            pass\n",
    "                        else:\n",
    "                            next_state -= 1\n",
    "                            state = next_state\n",
    "                        \n",
    "                \n",
    "                        n_syllables += syl_dic[next_obs]\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return emission, states\n",
    "\n",
    "    def rhyme_line(self, syl_dic, end_dic, number_to_word, word_to_number, seed): #Think of how to add syllable dictionary.\n",
    "        '''\n",
    "        Generates a sonnet line of ten syllables, without rhyme or meter\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "        emission = [seed]\n",
    "        state = np.random.choice(range(self.L), p = np.array(hmm_shakespeare_4.O)[:,word_to_number[seed]]/np.array(hmm_shakespeare_4.O)[:,word_to_number[seed]].sum()) #assuming uniform prior\n",
    "        states = []\n",
    "        states.append(state)\n",
    "        rand_var = random.uniform(0, 1)\n",
    "        next_state = 0\n",
    "        while rand_var > 0:\n",
    "            rand_var -= self.A[next_state][state]/np.array(self.A)[next_state,state].sum()\n",
    "            next_state += 1\n",
    "        if seed in end_dic.keys():\n",
    "            n_syllables = end_dic[seed]\n",
    "        else:\n",
    "            n_syllables = random.choice(syl_dic[seed])\n",
    "\n",
    "        while n_syllables < 10:\n",
    "            # Append state.\n",
    "            states.insert(0,state)\n",
    "            \n",
    "            #IMPORTANT: create a 'try' structure for n_syllables.\n",
    "            \n",
    "            # Sample next observation.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_obs = 0 \n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.O[state][next_obs]\n",
    "                next_obs += 1\n",
    "\n",
    "            next_obs -= 1                 \n",
    "            \n",
    "            #Obtain number of syllables for this word choice.\n",
    "            word_next_obs = number_to_word[next_obs]\n",
    "            new_syllable = random.choice(syl_dic[word_next_obs])\n",
    "            #end_syllable = 0\n",
    "            \n",
    "            #Check if selected word is an end-syllable case.\n",
    "            #if next_obs in end_dic.keys():\n",
    "            #    end_syllable = random.choice(end_dic[word_next_obs])\n",
    "            \n",
    "            if n_syllables + new_syllable > 10:\n",
    "                pass\n",
    "            else:\n",
    "                emission.insert(0,number_to_word[next_obs])\n",
    "\n",
    "                # Sample next state.\n",
    "                rand_var = random.uniform(0, np.array(self.A)[:,state].sum())\n",
    "                next_state = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= self.A[next_state][state]\n",
    "                    next_state += 1\n",
    "            \n",
    "                #Create end condition, n_syllables == 10.\n",
    "                if n_syllables + new_syllable == 10:\n",
    "                    pass\n",
    "                else:\n",
    "                    next_state -= 1\n",
    "                    state = next_state\n",
    "                \n",
    "                n_syllables += new_syllable\n",
    "        return emission, states\n",
    "    \n",
    "    def probability_alphas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using\n",
    "        the forward algorithm.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            prob:       Total probability that x can occur.\n",
    "        '''\n",
    "\n",
    "        # Calculate alpha vectors.\n",
    "        alphas = self.forward(x)\n",
    "\n",
    "        # alpha_j(M) gives the probability that the output sequence ends\n",
    "        # in j. Summing this value over all possible states j gives the\n",
    "        # total probability of x paired with any output sequence, i.e. the\n",
    "        # probability of x.\n",
    "        prob = sum(alphas[-1])\n",
    "        return prob\n",
    "\n",
    "\n",
    "    def probability_betas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using\n",
    "        the backward algorithm.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            prob:       Total probability that x can occur.\n",
    "        '''\n",
    "\n",
    "        betas = self.backward(x)\n",
    "\n",
    "        # beta_j(0) gives the probability of the output sequence. Summing\n",
    "        # this over all states and then normalizing gives the total\n",
    "        # probability of x paired with any output sequence, i.e. the\n",
    "        # probability of x.\n",
    "        prob = sum([betas[1][k] * self.A_start[k] * self.O[k][x[0]] \\\n",
    "            for k in range(self.L)])\n",
    "\n",
    "        return prob\n",
    "\n",
    "\n",
    "def supervised_HMM(X, Y):\n",
    "    '''\n",
    "    Helper function to train a supervised HMM. The function determines the\n",
    "    number of unique states and observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for supervised learning.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        Y:          A dataset consisting of state sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to L - 1. In other words, a list of lists.\n",
    "                    Note that the elements in X line up with those in Y.\n",
    "    '''\n",
    "\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "\n",
    "    # Make a set of states.\n",
    "    states = set()\n",
    "    for y in Y:\n",
    "        states |= set(y)\n",
    "    \n",
    "    # Compute L and D.\n",
    "    L = len(states)\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrices A and O.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with labeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.supervised_learning(X, Y)\n",
    "\n",
    "    return HMM\n",
    "\n",
    "\n",
    "def unsupervised_HMM(X, n_states, N_iters):\n",
    "    '''\n",
    "    Helper function to train an unsupervised HMM. The function determines the\n",
    "    number of unique observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for unsupervised learing.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        n_states:   Number of hidden states to use in training.\n",
    "        \n",
    "        N_iters:    The number of iterations to train on.\n",
    "    '''\n",
    "\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "    \n",
    "    # Compute L and D.\n",
    "    L = n_states\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrices A and O.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with unlabeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.unsupervised_learning(X, N_iters)\n",
    "\n",
    "    return HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_HMM(X, Y):\n",
    "    '''\n",
    "    Helper function to train a supervised HMM. The function determines the\n",
    "    number of unique states and observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for supervised learning.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        Y:          A dataset consisting of state sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to L - 1. In other words, a list of lists.\n",
    "                    Note that the elements in X line up with those in Y.\n",
    "    '''\n",
    "\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "        \n",
    "    # Make a set of states.\n",
    "    states = set()\n",
    "    for y in Y:\n",
    "        states |= set(y)\n",
    "    # Compute L and D.\n",
    "    L = len(states)\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrices A and O.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with labeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.supervised_learning(X, Y)\n",
    "\n",
    "    return HMM\n",
    "\n",
    "def unsupervised_HMM(X, n_states, N_iters):\n",
    "    '''\n",
    "    Helper function to train an unsupervised HMM. The function determines the\n",
    "    number of unique observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for unsupervised learing.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        n_states:   Number of hidden states to use in training.\n",
    "        \n",
    "        N_iters:    The number of iterations to train on.\n",
    "    '''\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "\n",
    "    # Compute L and D.\n",
    "    L = n_states\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrices A and O.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "    # Train an HMM with unlabeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.unsupervised_learning(X, N_iters)\n",
    "    return HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# CS/CNS/EE 155 2018\n",
    "# Problem Set 6\n",
    "#\n",
    "# Author:       Andrew Kang\n",
    "# Description:  Set 6 HMM helper\n",
    "########################################\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "####################\n",
    "# WORDCLOUD FUNCTIONS\n",
    "####################\n",
    "\n",
    "def mask():\n",
    "    # Parameters.\n",
    "    r = 128\n",
    "    d = 2 * r + 1\n",
    "\n",
    "    # Get points in a circle.\n",
    "    y, x = np.ogrid[-r:d-r, -r:d-r]\n",
    "    circle = (x**2 + y**2 <= r**2)\n",
    "\n",
    "    # Create mask.\n",
    "    mask = 255 * np.ones((d, d), dtype=np.uint8)\n",
    "    mask[circle] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "def text_to_wordcloud(text, max_words=50, title='', show=True):\n",
    "    plt.close('all')\n",
    "\n",
    "    # Generate a wordcloud image.\n",
    "    wordcloud = WordCloud(random_state=0,\n",
    "                          max_words=max_words,\n",
    "                          background_color='white',\n",
    "                          mask=mask()).generate(text)\n",
    "\n",
    "    # Show the image.\n",
    "    if show:\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=24)\n",
    "        plt.show()\n",
    "\n",
    "    return wordcloud\n",
    "\n",
    "def states_to_wordclouds(hmm, obs_map, max_words=50, show=True):\n",
    "    # Initialize.\n",
    "    M = 100000\n",
    "    n_states = len(hmm.A)\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    wordclouds = []\n",
    "\n",
    "    # Generate a large emission.\n",
    "    emission, states = hmm.generate_emission(M)\n",
    "\n",
    "    # For each state, get a list of observations that have been emitted\n",
    "    # from that state.\n",
    "    obs_count = []\n",
    "    for i in range(n_states):\n",
    "        obs_lst = np.array(emission)[np.where(np.array(states) == i)[0]]\n",
    "        obs_count.append(obs_lst)\n",
    "\n",
    "    # For each state, convert it into a wordcloud.\n",
    "    for i in range(n_states):\n",
    "        obs_lst = obs_count[i]\n",
    "        sentence = [obs_map_r[j] for j in obs_lst]\n",
    "        sentence_str = ' '.join(sentence)\n",
    "\n",
    "        wordclouds.append(text_to_wordcloud(sentence_str, max_words=max_words, title='State %d' % i, show=show))\n",
    "\n",
    "    return wordclouds\n",
    "\n",
    "\n",
    "####################\n",
    "# HMM FUNCTIONS\n",
    "####################\n",
    "\n",
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "def sample_sentence(hmm, obs_map, n_words=100):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "\n",
    "    # Sample and convert sentence.\n",
    "    emission, states = hmm.generate_emission(n_words)\n",
    "    sentence = [obs_map_r[i] for i in emission]\n",
    "\n",
    "    return ' '.join(sentence).capitalize() + '...'\n",
    "\n",
    "def write_naive_line(hmm, syl_dic, end_dic, number_to_word, word_to_number):\n",
    "    #Naively generate lines, without rhyme or meter.\n",
    "    obs_map_r = word_to_number\n",
    "    # Sample and convert sentence.\n",
    "    emission, states = hmm.naive_line(syl_dic, end_dic, number_to_word) \n",
    "    line = [number_to_word[i] for i in emission]\n",
    "    \n",
    "    return ' '.join(line).capitalize(), states\n",
    "\n",
    "def write_haiku_line(hmm, syl_dic, end_dic, number_to_word, word_to_number, num_syllables):\n",
    "    #Naively generate lines, without rhyme or meter.\n",
    "    obs_map_r = word_to_number\n",
    "    # Sample and convert sentence.\n",
    "    emission, states = hmm.haiku_line(syl_dic, end_dic, number_to_word,num_syllables) \n",
    "    line = [number_to_word[i] for i in emission]\n",
    "    return ' '.join(line).capitalize(), states\n",
    "\n",
    "####################\n",
    "# HMM VISUALIZATION FUNCTIONS\n",
    "####################\n",
    "\n",
    "def visualize_sparsities(hmm, O_max_cols=50, O_vmax=0.1):\n",
    "    plt.close('all')\n",
    "    plt.set_cmap('viridis')\n",
    "\n",
    "    # Visualize sparsity of A.\n",
    "    plt.imshow(hmm.A, vmax=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of A matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize parsity of O.\n",
    "    plt.imshow(np.array(hmm.O)[:, :O_max_cols], vmax=O_vmax, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of O matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "####################\n",
    "# HMM ANIMATION FUNCTIONS\n",
    "####################\n",
    "\n",
    "def animate_emission(hmm, obs_map, M=8, height=12, width=12, delay=1):\n",
    "    # Parameters.\n",
    "    lim = 1200\n",
    "    text_x_offset = 40\n",
    "    text_y_offset = 80\n",
    "    x_offset = 580\n",
    "    y_offset = 520\n",
    "    R = 420\n",
    "    r = 100\n",
    "    arrow_size = 20\n",
    "    arrow_p1 = 0.03\n",
    "    arrow_p2 = 0.02\n",
    "    arrow_p3 = 0.06\n",
    "    \n",
    "    # Initialize.\n",
    "    n_states = len(hmm.A)\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    wordclouds = states_to_wordclouds(hmm, obs_map, max_words=20, show=False)\n",
    "\n",
    "    # Initialize plot.    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(height)\n",
    "    fig.set_figwidth(width)\n",
    "    ax.grid('off')\n",
    "    plt.axis('off')\n",
    "    ax.set_xlim([0, lim])\n",
    "    ax.set_ylim([0, lim])\n",
    "\n",
    "    # Plot each wordcloud.\n",
    "    for i, wordcloud in enumerate(wordclouds):\n",
    "        x = x_offset + int(R * np.cos(np.pi * 2 * i / n_states))\n",
    "        y = y_offset + int(R * np.sin(np.pi * 2 * i / n_states))\n",
    "        ax.imshow(wordcloud.to_array(), extent=(x - r, x + r, y - r, y + r), aspect='auto', zorder=-1)\n",
    "\n",
    "    # Initialize text.\n",
    "    text = ax.text(text_x_offset, lim - text_y_offset, '', fontsize=24)\n",
    "        \n",
    "    # Make the arrows.\n",
    "    zorder_mult = n_states ** 2 * 100\n",
    "    arrows = []\n",
    "    for i in range(n_states):\n",
    "        row = []\n",
    "        for j in range(n_states):\n",
    "            # Arrow coordinates.\n",
    "            x_i = x_offset + R * np.cos(np.pi * 2 * i / n_states)\n",
    "            y_i = y_offset + R * np.sin(np.pi * 2 * i / n_states)\n",
    "            x_j = x_offset + R * np.cos(np.pi * 2 * j / n_states)\n",
    "            y_j = y_offset + R * np.sin(np.pi * 2 * j / n_states)\n",
    "            \n",
    "            dx = x_j - x_i\n",
    "            dy = y_j - y_i\n",
    "            d = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "            if i != j:\n",
    "                arrow = ax.arrow(x_i + (r/d + arrow_p1) * dx + arrow_p2 * dy,\n",
    "                                 y_i + (r/d + arrow_p1) * dy + arrow_p2 * dx,\n",
    "                                 (1 - 2 * r/d - arrow_p3) * dx,\n",
    "                                 (1 - 2 * r/d - arrow_p3) * dy,\n",
    "                                 color=(1 - hmm.A[i][j], ) * 3,\n",
    "                                 head_width=arrow_size, head_length=arrow_size,\n",
    "                                 zorder=int(hmm.A[i][j] * zorder_mult))\n",
    "            else:\n",
    "                arrow = ax.arrow(x_i, y_i, 0, 0,\n",
    "                                 color=(1 - hmm.A[i][j], ) * 3,\n",
    "                                 head_width=arrow_size, head_length=arrow_size,\n",
    "                                 zorder=int(hmm.A[i][j] * zorder_mult))\n",
    "\n",
    "            row.append(arrow)\n",
    "        arrows.append(row)\n",
    "\n",
    "    emission, states = hmm.generate_emission(M)\n",
    "\n",
    "    def animate(i):\n",
    "        if i >= delay:\n",
    "            i -= delay\n",
    "\n",
    "            if i == 0:\n",
    "                arrows[states[0]][states[0]].set_color('red')\n",
    "            elif i == 1:\n",
    "                arrows[states[0]][states[0]].set_color((1 - hmm.A[states[0]][states[0]], ) * 3)\n",
    "                arrows[states[i - 1]][states[i]].set_color('red')\n",
    "            else:\n",
    "                arrows[states[i - 2]][states[i - 1]].set_color((1 - hmm.A[states[i - 2]][states[i - 1]], ) * 3)\n",
    "                arrows[states[i - 1]][states[i]].set_color('red')\n",
    "\n",
    "            # Set text.\n",
    "            text.set_text(' '.join([obs_map_r[e] for e in emission][:i+1]).capitalize())\n",
    "\n",
    "            return arrows + [text]\n",
    "\n",
    "    # Animate!\n",
    "    print('\\nAnimating...')\n",
    "    anim = FuncAnimation(fig, animate, frames=M+delay, interval=1000)\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n"
     ]
    }
   ],
   "source": [
    "hmm_shakespeare_4 = unsupervised_HMM(shakespeare_lines_token, 16, 100)\n",
    "#hmm_spenser_32 = unsupervised_HMM(spenser, 32, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 14-line sonnets. Currently pseudocode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\",\",\".\",\";\",\":\",\"!\",\"'\",\"’\",\"(\",\")\",\"?\",\" \"]\n",
    "punctuation_probs = np.zeros(len(\",.;:!'’()?\")+1) #,.;:!'’()?none\n",
    "for i in range(len(shakespeare_lines)):\n",
    "    last_element = shakespeare_lines[i][-1]\n",
    "    if last_element == \",\":\n",
    "        punctuation_probs[0] += 1\n",
    "    elif last_element == \".\":\n",
    "        punctuation_probs[1] += 1\n",
    "    elif last_element == \";\":\n",
    "        punctuation_probs[2] += 1\n",
    "    elif last_element == \":\":\n",
    "        punctuation_probs[3] += 1\n",
    "    elif last_element == \"!\":\n",
    "        punctuation_probs[4] += 1\n",
    "    elif last_element == \"'\":\n",
    "        punctuation_probs[5] += 1\n",
    "    elif last_element == \"’\":\n",
    "        punctuation_probs[6] += 1\n",
    "    elif last_element == \"(\":\n",
    "        punctuation_probs[7] += 1\n",
    "    elif last_element == \")\":\n",
    "        punctuation_probs[8] += 1\n",
    "    elif last_element == \"?\":\n",
    "        punctuation_probs[9] += 1\n",
    "    else:\n",
    "        punctuation_probs[10] += 1\n",
    "punctuation_probs = punctuation_probs/float(punctuation_probs.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shakespeare_naive(hmm): #Takes trained HMM as input.\n",
    "    #No rhyme here, only constraining number of syllables and lines.\n",
    "    sonnet = ''\n",
    "    hidden_arr = []\n",
    "    for i in np.arange(14):\n",
    "        line, h_states = write_naive_line(hmm, syllables_notend_dict, syllables_end_dict, numbertoword_dict, wordtonumber_dict)\n",
    "        sonnet += line + np.random.choice(punctuation, p=punctuation_probs) + ' \\n ' #Waiting on Chris for punctuation.\n",
    "        hidden_arr.append(h_states)\n",
    "    return sonnet, hidden_arr\n",
    "\n",
    "def Shakespeare_haiku(hmm): #Takes trained HMM as input.\n",
    "    #No rhyme here, only constraining number of syllables and lines.\n",
    "    sonnet = ''\n",
    "    hidden_arr = []\n",
    "    for i in [5,7,5]:\n",
    "        line, h_states = write_haiku_line(hmm, syllables_notend_dict, syllables_end_dict, numbertoword_dict, wordtonumber_dict,i)\n",
    "        sonnet += line + ' \\n ' #Waiting on Chris for punctuation.\n",
    "        hidden_arr.append(h_states)\n",
    "    return sonnet, hidden_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'forward', 'violet', 'thus', 'did', 'I', 'chide', ',']\n",
      "['But', 'sweet', ',', 'or', 'colour', 'it', 'had', \"stol'n\", 'from', 'thee', '.']\n",
      "['O', 'thou', 'my', 'lovely', 'boy', 'who', 'in', 'thy', 'power', ',']\n",
      "['And', 'her', 'quietus', 'is', 'to', 'render', 'thee', '.']\n",
      "[1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386]\n",
      "[1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762]\n"
     ]
    }
   ],
   "source": [
    "badone_begin = 98*14 \n",
    "badone_end = badone_begin + 14\n",
    "badtwo_begin = badone_end + 14*(125-99) + 1\n",
    "badtwo_end = badtwo_begin + 11\n",
    "print(shakespeare_lines[badone_begin])\n",
    "print(shakespeare_lines[badone_end])\n",
    "print(shakespeare_lines[badtwo_begin])\n",
    "print(shakespeare_lines[badtwo_end])\n",
    "#print(badone_begin, badone_end, badtwo_begin, badtwo_end)\n",
    "print(np.arange(badone_begin, badone_end + 1))\n",
    "print(np.arange(badtwo_begin, badtwo_end + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sonnets = 154\n",
    "usable_lines = [] #Remove the 12-line and 15-line sonnets, 99 and 126.\n",
    "for i in np.arange(len(shakespeare_lines)):\n",
    "    if i in np.arange(badone_begin, badone_end + 1):\n",
    "        pass\n",
    "    elif i in np.arange(badtwo_begin, badtwo_end + 1):\n",
    "        pass\n",
    "    else:\n",
    "        usable_lines.append(i)  \n",
    "\n",
    "num_lines = len(usable_lines)\n",
    "num_sonnets = num_lines/14 #Should be 152, 154 minus the two oddballs.\n",
    "   \n",
    "rhyming_keys = []\n",
    "punctuations = range(3205,3214)\n",
    "    \n",
    "for i in np.arange(num_sonnets):\n",
    "    \n",
    "    #Don't include punctuation\n",
    "    for j in np.arange(3):\n",
    "        \n",
    "        #word1 = shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-1]\n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-1] in punctuations:\n",
    "            if shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-2] in punctuations:\n",
    "                word1 = shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-3]\n",
    "            else:\n",
    "                word1 = shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-2]\n",
    "        else:\n",
    "            word1 = shakespeare_lines_token[usable_lines[int(14*i + 4*j)]][-1]   \n",
    "        \n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 2 + 4*j)]][-1] in punctuations:\n",
    "            if shakespeare_lines_token[usable_lines[int(14*i + 2 + 4*j)]][-2] in punctuations:\n",
    "                word2 = shakespeare_lines_token[usable_lines[int(14*i + 2 + 4*j)]][-3]\n",
    "            else:\n",
    "                word2 = shakespeare_lines_token[usable_lines[int(14*i + 2 + 4*j)]][-2]\n",
    "        else:\n",
    "            word2 = shakespeare_lines_token[usable_lines[int(14*i + 2 + 4*j)]][-1]   \n",
    "            \n",
    "        rhyming_keys.append([word1, word2])\n",
    "\n",
    "        \n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 1 + 4*j)]][-1] in punctuations:\n",
    "            if shakespeare_lines_token[usable_lines[int(14*i + 1 + 4*j)]][-2] in punctuations:\n",
    "                word3 = shakespeare_lines_token[usable_lines[int(14*i + 1 + 4*j)]][-3]\n",
    "            else:\n",
    "                word3 = shakespeare_lines_token[usable_lines[int(14*i + 1 + 4*j)]][-2]\n",
    "        else:\n",
    "            word3 = shakespeare_lines_token[usable_lines[int(14*i + 1 + 4*j)]][-1]           \n",
    "        \n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 3 + 4*j)]][-1] in punctuations:\n",
    "            if shakespeare_lines_token[usable_lines[int(14*i + 3 + 4*j)]][-2] in punctuations:\n",
    "                word4 = shakespeare_lines_token[usable_lines[int(14*i + 3 + 4*j)]][-3]\n",
    "            else:\n",
    "                word4 = shakespeare_lines_token[usable_lines[int(14*i + 3 + 4*j)]][-2]\n",
    "        else:\n",
    "            word4 = shakespeare_lines_token[usable_lines[int(14*i + 3 + 4*j)]][-1]   \n",
    "        \n",
    "        rhyming_keys.append([word3, word4])    \n",
    "            \n",
    "            \n",
    "    if shakespeare_lines_token[usable_lines[int(14*i) + 12]][-1] in punctuations:\n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 12)]][-2] in punctuations:\n",
    "            couplet1 = shakespeare_lines_token[usable_lines[int(14*i + 12)]][-3]\n",
    "        else:\n",
    "            couplet1 = shakespeare_lines_token[usable_lines[int(14*i + 12)]][-2]\n",
    "    else:\n",
    "        couplet1 = shakespeare_lines_token[usable_lines[int(14*i + 12)]][-1]  \n",
    "        \n",
    "    if shakespeare_lines_token[usable_lines[int(14*i) + 13]][-1] in punctuations:\n",
    "        if shakespeare_lines_token[usable_lines[int(14*i + 13)]][-2] in punctuations:\n",
    "            couplet2 = shakespeare_lines_token[usable_lines[int(14*i + 13)]][-3]\n",
    "        else:\n",
    "            couplet2 = shakespeare_lines_token[usable_lines[int(14*i + 13)]][-2]\n",
    "    else:\n",
    "        couplet2 = shakespeare_lines_token[usable_lines[int(14*i + 13)]][-1]    \n",
    "        \n",
    "    rhyming_keys.append([couplet1, couplet2])\n",
    "\n",
    "rhyming_words = []\n",
    "for i in np.arange(len(rhyming_keys)):\n",
    "    rhyming_words.append([numbertoword_dict[rhyming_keys[i][0]], \\\n",
    "                          numbertoword_dict[rhyming_keys[i][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['increase', 'decease'],\n",
       " ['die', 'memory'],\n",
       " ['eyes', 'lies'],\n",
       " ['fuel', 'cruel'],\n",
       " ['ornament', 'content'],\n",
       " ['spring', 'niggarding'],\n",
       " ['be', 'thee'],\n",
       " ['brow', 'now'],\n",
       " ['field', 'held'],\n",
       " ['lies', 'eyes'],\n",
       " ['days', 'praise'],\n",
       " ['use', 'excuse'],\n",
       " ['mine', 'thine'],\n",
       " ['old', 'cold'],\n",
       " ['viewest', 'renewest'],\n",
       " ['another', 'mother'],\n",
       " ['womb', 'tomb'],\n",
       " ['husbandry', 'posterity'],\n",
       " ['thee', 'see'],\n",
       " ['prime', 'time'],\n",
       " ['be', 'thee'],\n",
       " ['spend', 'lend'],\n",
       " ['legacy', 'free'],\n",
       " ['abuse', 'use'],\n",
       " ['give', 'live'],\n",
       " ['alone', 'gone'],\n",
       " ['deceive', 'leave'],\n",
       " ['thee', 'be'],\n",
       " ['frame', 'same'],\n",
       " ['dwell', 'excel'],\n",
       " ['on', 'gone'],\n",
       " ['there', 'where'],\n",
       " ['left', 'bereft'],\n",
       " ['glass', 'was'],\n",
       " ['meet', 'sweet'],\n",
       " ['deface', 'place'],\n",
       " ['distilled', 'self-killed'],\n",
       " ['usury', 'thee'],\n",
       " ['loan', 'one'],\n",
       " ['art', 'depart'],\n",
       " ['thee', 'posterity'],\n",
       " ['fair', 'heir'],\n",
       " ['light', 'sight'],\n",
       " ['eye', 'majesty'],\n",
       " ['hill', 'still'],\n",
       " ['age', 'pilgrimage'],\n",
       " ['car', 'are'],\n",
       " ['day', 'way'],\n",
       " ['noon', 'son'],\n",
       " ['sadly', 'gladly'],\n",
       " ['joy', 'annoy'],\n",
       " ['sounds', 'confounds'],\n",
       " ['ear', 'bear'],\n",
       " ['another', 'mother'],\n",
       " ['ordering', 'sing'],\n",
       " ['one', 'none'],\n",
       " ['eye', 'die'],\n",
       " ['life', 'wife'],\n",
       " ['weep', 'keep'],\n",
       " ['behind', 'mind'],\n",
       " ['spend', 'end'],\n",
       " ['it', 'it'],\n",
       " ['sits', 'commits'],\n",
       " ['any', 'many'],\n",
       " ['unprovident', 'evident'],\n",
       " ['hate', 'ruinate'],\n",
       " ['conspire', 'desire'],\n",
       " ['mind', 'kind'],\n",
       " ['love', 'prove'],\n",
       " ['me', 'thee'],\n",
       " [\"grow'st\", \"bestow'st\"],\n",
       " ['departest', 'convertest'],\n",
       " ['increase', 'cease'],\n",
       " ['decay', 'away'],\n",
       " ['store', 'more'],\n",
       " ['perish', 'cherish'],\n",
       " ['thereby', 'die'],\n",
       " ['time', 'prime'],\n",
       " ['night', 'white'],\n",
       " ['leaves', 'sheaves'],\n",
       " ['herd', 'beard'],\n",
       " ['make', 'forsake'],\n",
       " ['go', 'grow'],\n",
       " ['defence', 'hence'],\n",
       " ['are', 'prepare'],\n",
       " ['live', 'give'],\n",
       " ['lease', 'decease'],\n",
       " ['were', 'bear'],\n",
       " ['decay', 'day'],\n",
       " ['uphold', 'cold'],\n",
       " ['know', 'so'],\n",
       " ['pluck', 'luck'],\n",
       " ['astronomy', 'quality'],\n",
       " ['tell', 'well'],\n",
       " ['wind', 'find'],\n",
       " ['derive', 'thrive'],\n",
       " ['art', 'convert'],\n",
       " ['prognosticate', 'date'],\n",
       " ['grows', 'shows'],\n",
       " ['moment', 'comment'],\n",
       " ['increase', 'decrease'],\n",
       " ['sky', 'memory'],\n",
       " ['stay', 'decay'],\n",
       " ['sight', 'night'],\n",
       " ['you', 'new'],\n",
       " ['way', 'decay'],\n",
       " ['time', 'rhyme'],\n",
       " ['hours', 'flowers'],\n",
       " ['unset', 'counterfeit'],\n",
       " ['repair', 'fair'],\n",
       " ['pen', 'men'],\n",
       " ['still', 'skill'],\n",
       " ['come', 'tomb'],\n",
       " ['deserts', 'parts'],\n",
       " ['eyes', 'lies'],\n",
       " ['graces', 'faces'],\n",
       " ['age', 'rage'],\n",
       " ['tongue', 'song'],\n",
       " ['time', 'rhyme'],\n",
       " ['day', 'may'],\n",
       " ['temperate', 'date'],\n",
       " ['shines', 'declines'],\n",
       " ['dimmed', 'untrimmed'],\n",
       " ['fade', 'shade'],\n",
       " [\"ow'st\", \"grow'st\"],\n",
       " ['see', 'thee'],\n",
       " ['paws', 'jaws'],\n",
       " ['brood', 'blood'],\n",
       " [\"fleet'st\", 'sweets'],\n",
       " ['time', 'crime'],\n",
       " ['brow', 'allow'],\n",
       " ['pen', 'men'],\n",
       " ['wrong', 'young'],\n",
       " ['painted', 'acquainted'],\n",
       " ['passion', 'fashion'],\n",
       " ['rolling', 'controlling'],\n",
       " ['gazeth', 'amazeth'],\n",
       " ['created', 'defeated'],\n",
       " ['a-doting', 'nothing'],\n",
       " ['pleasure', 'treasure'],\n",
       " ['muse', 'use'],\n",
       " ['verse', 'rehearse'],\n",
       " ['compare', 'rare'],\n",
       " ['gems', 'hems'],\n",
       " ['write', 'bright'],\n",
       " ['fair', 'air'],\n",
       " ['well', 'sell'],\n",
       " ['old', 'behold'],\n",
       " ['date', 'expiate'],\n",
       " ['thee', 'me'],\n",
       " ['heart', 'art'],\n",
       " ['wary', 'chary'],\n",
       " ['will', 'ill'],\n",
       " ['slain', 'again'],\n",
       " ['stage', 'rage'],\n",
       " ['part', 'heart'],\n",
       " ['say', 'decay'],\n",
       " ['rite', 'might'],\n",
       " ['eloquence', 'recompense'],\n",
       " ['breast', 'expressed'],\n",
       " ['writ', 'wit'],\n",
       " ['stelled', 'held'],\n",
       " ['heart', 'art'],\n",
       " ['skill', 'still'],\n",
       " ['lies', 'eyes'],\n",
       " ['done', 'sun'],\n",
       " ['me', 'thee'],\n",
       " ['art', 'heart'],\n",
       " ['stars', 'bars'],\n",
       " ['boast', 'most'],\n",
       " ['spread', 'buried'],\n",
       " ['eye', 'die'],\n",
       " ['fight', 'quite'],\n",
       " ['foiled', 'toiled'],\n",
       " ['beloved', 'removed'],\n",
       " ['vassalage', 'embassage'],\n",
       " ['knit', 'wit'],\n",
       " ['mine', 'thine'],\n",
       " ['it', 'it'],\n",
       " ['moving', 'loving'],\n",
       " ['aspect', 'respect'],\n",
       " ['thee', 'me'],\n",
       " ['bed', 'head'],\n",
       " ['tired', 'expired'],\n",
       " ['abide', 'wide'],\n",
       " ['thee', 'see'],\n",
       " ['sight', 'night'],\n",
       " ['view', 'new'],\n",
       " ['mind', 'find'],\n",
       " ['plight', 'night'],\n",
       " ['rest', 'oppressed'],\n",
       " ['reign', 'complain'],\n",
       " ['me', 'thee'],\n",
       " ['bright', 'night'],\n",
       " ['heaven', 'even'],\n",
       " ['longer', 'stronger'],\n",
       " ['eyes', 'cries'],\n",
       " ['state', 'fate'],\n",
       " ['hope', 'scope'],\n",
       " ['possessed', 'least'],\n",
       " ['despising', 'arising'],\n",
       " ['state', 'gate'],\n",
       " ['brings', 'kings'],\n",
       " ['thought', 'sought'],\n",
       " ['past', 'waste'],\n",
       " ['flow', 'woe'],\n",
       " ['night', 'sight'],\n",
       " ['foregone', 'moan'],\n",
       " [\"o'er\", 'before'],\n",
       " ['friend', 'end'],\n",
       " ['hearts', 'parts'],\n",
       " ['dead', 'buried'],\n",
       " ['tear', 'appear'],\n",
       " ['eye', 'lie'],\n",
       " ['live', 'give'],\n",
       " ['gone', 'alone'],\n",
       " ['thee', 'me'],\n",
       " ['day', 're-survey'],\n",
       " ['cover', 'lover'],\n",
       " ['time', 'rhyme'],\n",
       " ['pen', 'men'],\n",
       " ['thought', 'brought'],\n",
       " ['age', 'equipage'],\n",
       " ['prove', 'love'],\n",
       " ['seen', 'green'],\n",
       " ['eye', 'alchemy'],\n",
       " ['ride', 'hide'],\n",
       " ['face', 'disgrace'],\n",
       " ['shine', 'mine'],\n",
       " ['brow', 'now'],\n",
       " ['disdaineth', 'staineth'],\n",
       " ['day', 'way'],\n",
       " ['cloak', 'smoke'],\n",
       " ['break', 'speak'],\n",
       " ['face', 'disgrace'],\n",
       " ['grief', 'relief'],\n",
       " ['loss', 'cross'],\n",
       " ['sheds', 'deeds'],\n",
       " ['done', 'sun'],\n",
       " ['mud', 'bud'],\n",
       " ['this', 'amiss'],\n",
       " ['compare', 'are'],\n",
       " ['sense', 'commence'],\n",
       " ['advocate', 'hate'],\n",
       " ['be', 'me'],\n",
       " ['twain', 'remain'],\n",
       " ['one', 'alone'],\n",
       " ['respect', 'effect'],\n",
       " ['spite', 'delight'],\n",
       " ['thee', 'me'],\n",
       " ['shame', 'name'],\n",
       " ['sort', 'report'],\n",
       " ['delight', 'spite'],\n",
       " ['youth', 'truth'],\n",
       " ['wit', 'sit'],\n",
       " ['more', 'store'],\n",
       " ['despised', 'sufficed'],\n",
       " ['give', 'live'],\n",
       " ['thee', 'me'],\n",
       " ['invent', 'excellent'],\n",
       " ['verse', 'rehearse'],\n",
       " ['me', 'thee'],\n",
       " ['sight', 'light'],\n",
       " ['worth', 'forth'],\n",
       " ['invocate', 'date'],\n",
       " ['days', 'praise'],\n",
       " ['sing', 'bring'],\n",
       " ['me', 'thee'],\n",
       " ['live', 'give'],\n",
       " ['one', 'alone'],\n",
       " ['prove', 'love'],\n",
       " ['leave', 'deceive'],\n",
       " ['twain', 'remain'],\n",
       " ['all', 'call'],\n",
       " ['before', 'more'],\n",
       " ['receivest', 'deceivest'],\n",
       " ['usest', 'refusest'],\n",
       " ['thief', 'grief'],\n",
       " ['poverty', 'injury'],\n",
       " ['shows', 'foes'],\n",
       " ['commits', 'befits'],\n",
       " ['heart', 'art'],\n",
       " ['won', 'son'],\n",
       " ['assailed', 'prevailed'],\n",
       " ['forbear', 'there'],\n",
       " ['youth', 'truth'],\n",
       " ['thee', 'me'],\n",
       " ['grief', 'chief'],\n",
       " ['dearly', 'nearly'],\n",
       " ['ye', 'me'],\n",
       " ['her', 'her'],\n",
       " ['gain', 'twain'],\n",
       " ['loss', 'cross'],\n",
       " ['one', 'alone'],\n",
       " ['see', 'thee'],\n",
       " ['unrespected', 'directed'],\n",
       " ['bright', 'light'],\n",
       " ['show', 'so'],\n",
       " ['made', 'shade'],\n",
       " ['day', 'stay'],\n",
       " ['thee', 'me'],\n",
       " ['thought', 'brought'],\n",
       " ['way', 'stay'],\n",
       " ['stand', 'land'],\n",
       " ['thee', 'be'],\n",
       " ['thought', 'wrought'],\n",
       " ['gone', 'moan'],\n",
       " ['slow', 'woe'],\n",
       " ['fire', 'desire'],\n",
       " ['abide', 'slide'],\n",
       " ['gone', 'alone'],\n",
       " ['thee', 'melancholy'],\n",
       " ['recured', 'assured'],\n",
       " ['thee', 'me'],\n",
       " ['glad', 'sad'],\n",
       " ['war', 'bar'],\n",
       " ['sight', 'right'],\n",
       " ['lie', 'deny'],\n",
       " ['eyes', 'lies'],\n",
       " ['impanelled', 'determined'],\n",
       " ['heart', 'part'],\n",
       " ['part', 'heart'],\n",
       " ['took', 'look'],\n",
       " ['other', 'smother'],\n",
       " ['feast', 'guest'],\n",
       " ['heart', 'part'],\n",
       " ['love', 'move'],\n",
       " ['me', 'thee'],\n",
       " ['sight', 'delight'],\n",
       " ['way', 'stay'],\n",
       " ['thrust', 'trust'],\n",
       " ['are', 'care'],\n",
       " ['grief', 'thief'],\n",
       " ['chest', 'breast'],\n",
       " ['art', 'part'],\n",
       " ['fear', 'dear'],\n",
       " ['come', 'sum'],\n",
       " ['defects', 'respects'],\n",
       " ['pass', 'was'],\n",
       " ['eye', 'gravity'],\n",
       " ['here', 'uprear'],\n",
       " ['desert', 'part'],\n",
       " ['laws', 'cause'],\n",
       " ['way', 'say'],\n",
       " ['end', 'friend'],\n",
       " ['woe', 'know'],\n",
       " ['me', 'thee'],\n",
       " ['on', 'groan'],\n",
       " ['hide', 'side'],\n",
       " ['mind', 'behind'],\n",
       " ['offence', 'thence'],\n",
       " ['speed', 'need'],\n",
       " ['find', 'wind'],\n",
       " ['slow', 'know'],\n",
       " ['pace', 'race'],\n",
       " ['made', 'jade'],\n",
       " ['wilful-slow', 'go'],\n",
       " ['key', 'survey'],\n",
       " ['treasure', 'pleasure'],\n",
       " ['rare', 'are'],\n",
       " ['set', 'carcanet'],\n",
       " ['chest', 'special-blest'],\n",
       " ['hide', 'pride'],\n",
       " ['scope', 'hope'],\n",
       " ['made', 'shade'],\n",
       " ['tend', 'lend'],\n",
       " ['counterfeit', 'set'],\n",
       " ['you', 'new'],\n",
       " ['year', 'appear'],\n",
       " ['show', 'know'],\n",
       " ['part', 'heart'],\n",
       " ['seem', 'deem'],\n",
       " ['give', 'live'],\n",
       " ['dye', 'wantonly'],\n",
       " ['roses', 'discloses'],\n",
       " ['show', 'so'],\n",
       " ['fade', 'made'],\n",
       " ['youth', 'truth'],\n",
       " ['monuments', 'contents'],\n",
       " ['rhyme', 'time'],\n",
       " ['overturn', 'burn'],\n",
       " ['masonry', 'memory'],\n",
       " ['enmity', 'posterity'],\n",
       " ['room', 'doom'],\n",
       " ['arise', 'eyes'],\n",
       " ['said', 'allayed'],\n",
       " ['appetite', 'might'],\n",
       " ['fill', 'kill'],\n",
       " ['fulness', 'dulness'],\n",
       " ['be', 'see'],\n",
       " ['new', 'view'],\n",
       " ['care', 'rare'],\n",
       " ['tend', 'spend'],\n",
       " ['desire', 'require'],\n",
       " ['hour', 'sour'],\n",
       " ['you', 'adieu'],\n",
       " ['thought', 'nought'],\n",
       " ['suppose', 'those'],\n",
       " ['will', 'ill'],\n",
       " ['slave', 'crave'],\n",
       " ['pleasure', 'leisure'],\n",
       " ['beck', 'check'],\n",
       " ['liberty', 'injury'],\n",
       " ['strong', 'belong'],\n",
       " ['time', 'crime'],\n",
       " ['hell', 'well'],\n",
       " ['is', 'amis'],\n",
       " ['beguiled', 'child'],\n",
       " ['look', 'book'],\n",
       " ['sun', 'done'],\n",
       " ['say', 'they'],\n",
       " ['frame', 'same'],\n",
       " ['days', 'praise'],\n",
       " ['shore', 'before'],\n",
       " ['end', 'contend'],\n",
       " ['light', 'fight'],\n",
       " ['crowned', 'confound'],\n",
       " ['youth', 'truth'],\n",
       " ['brow', 'mow'],\n",
       " ['stand', 'hand'],\n",
       " ['open', 'broken'],\n",
       " ['night', 'sight'],\n",
       " ['thee', 'me'],\n",
       " ['pry', 'jealousy'],\n",
       " ['great', 'defeat'],\n",
       " ['awake', 'sake'],\n",
       " ['elsewhere', 'near'],\n",
       " ['eye', 'remedy'],\n",
       " ['part', 'heart'],\n",
       " ['mine', 'define'],\n",
       " ['account', 'surmount'],\n",
       " ['indeed', 'read'],\n",
       " ['antiquity', 'iniquity'],\n",
       " ['praise', 'days'],\n",
       " ['now', 'brow'],\n",
       " [\"o'erworn\", 'morn'],\n",
       " ['night', 'sight'],\n",
       " ['king', 'spring'],\n",
       " ['fortify', 'memory'],\n",
       " ['knife', 'life'],\n",
       " ['seen', 'green'],\n",
       " ['defaced', 'down-rased'],\n",
       " ['age', 'rage'],\n",
       " ['gain', 'main'],\n",
       " ['shore', 'store'],\n",
       " ['state', 'ruminate'],\n",
       " ['decay', 'away'],\n",
       " ['choose', 'lose'],\n",
       " ['sea', 'plea'],\n",
       " ['power', 'flower'],\n",
       " ['out', 'stout'],\n",
       " ['days', 'decays'],\n",
       " ['alack', 'back'],\n",
       " ['hid', 'forbid'],\n",
       " ['might', 'bright'],\n",
       " ['cry', 'jollity'],\n",
       " ['born', 'forsworn'],\n",
       " ['misplaced', 'disgraced'],\n",
       " ['strumpeted', 'disabled'],\n",
       " ['authority', 'simplicity'],\n",
       " ['skill', 'ill'],\n",
       " ['gone', 'alone'],\n",
       " ['live', 'achieve'],\n",
       " ['impiety', 'society'],\n",
       " ['cheek', 'seek'],\n",
       " ['hue', 'true'],\n",
       " ['is', 'his'],\n",
       " ['veins', 'gains'],\n",
       " ['had', 'bad'],\n",
       " ['outworn', 'born'],\n",
       " ['now', 'brow'],\n",
       " ['dead', 'head'],\n",
       " ['away', 'gay'],\n",
       " ['seen', 'green'],\n",
       " ['true', 'new'],\n",
       " ['store', 'yore'],\n",
       " ['view', 'due'],\n",
       " ['mend', 'commend'],\n",
       " ['crowned', 'confound'],\n",
       " ['own', 'shown'],\n",
       " ['mind', 'kind'],\n",
       " ['deeds', 'weeds'],\n",
       " ['show', 'grow'],\n",
       " ['defect', 'suspect'],\n",
       " ['fair', 'air'],\n",
       " ['approve', 'love'],\n",
       " ['time', 'prime'],\n",
       " ['days', 'praise'],\n",
       " ['charged', 'enlarged'],\n",
       " ['show', 'owe'],\n",
       " ['dead', 'fled'],\n",
       " ['bell', 'dwell'],\n",
       " ['not', 'forgot'],\n",
       " ['so', 'woe'],\n",
       " ['verse', 'rehearse'],\n",
       " ['clay', 'decay'],\n",
       " ['moan', 'gone'],\n",
       " ['recite', 'quite'],\n",
       " ['love', 'prove'],\n",
       " ['lie', 'i'],\n",
       " ['desert', 'impart'],\n",
       " ['this', 'is'],\n",
       " ['untrue', 'you'],\n",
       " ['forth', 'worth'],\n",
       " ['behold', 'cold'],\n",
       " ['hang', 'sang'],\n",
       " ['day', 'away'],\n",
       " ['west', 'rest'],\n",
       " ['fire', 'expire'],\n",
       " ['lie', 'by'],\n",
       " ['strong', 'long'],\n",
       " ['arrest', 'interest'],\n",
       " ['away', 'stay'],\n",
       " ['review', 'due'],\n",
       " ['thee', 'me'],\n",
       " ['life', 'knife'],\n",
       " ['dead', 'remembered'],\n",
       " ['contains', 'remains'],\n",
       " ['life', 'strife'],\n",
       " ['ground', 'found'],\n",
       " ['anon', 'alone'],\n",
       " ['treasure', 'pleasure'],\n",
       " ['sight', 'delight'],\n",
       " ['look', 'took'],\n",
       " ['day', 'away'],\n",
       " ['pride', 'aside'],\n",
       " ['change', 'strange'],\n",
       " ['same', 'name'],\n",
       " ['weed', 'proceed'],\n",
       " ['you', 'new'],\n",
       " ['argument', 'spent'],\n",
       " ['old', 'told'],\n",
       " ['wear', 'bear'],\n",
       " ['waste', 'taste'],\n",
       " ['show', 'know'],\n",
       " ['memory', 'eternity'],\n",
       " ['contain', 'brain'],\n",
       " ['find', 'mind'],\n",
       " ['look', 'book'],\n",
       " ['muse', 'use'],\n",
       " ['verse', 'disperse'],\n",
       " ['sing', 'wing'],\n",
       " ['fly', 'majesty'],\n",
       " ['compile', 'style'],\n",
       " ['thee', 'be'],\n",
       " ['advance', 'ignorance'],\n",
       " ['aid', 'decayed'],\n",
       " ['grace', 'place'],\n",
       " ['argument', 'invent'],\n",
       " ['pen', 'again'],\n",
       " ['word', 'afford'],\n",
       " ['give', 'live'],\n",
       " ['say', 'pay'],\n",
       " ['write', 'might'],\n",
       " ['name', 'fame'],\n",
       " ['is', 'his'],\n",
       " ['bear', 'appear'],\n",
       " ['afloat', 'boat'],\n",
       " ['ride', 'pride'],\n",
       " ['away', 'decay'],\n",
       " ['make', 'take'],\n",
       " ['rotten', 'forgotten'],\n",
       " ['have', 'grave'],\n",
       " ['die', 'lie'],\n",
       " ['verse', 'rehearse'],\n",
       " [\"o'er-read\", 'dead'],\n",
       " ['pen', 'men'],\n",
       " ['muse', 'use'],\n",
       " [\"o'erlook\", 'book'],\n",
       " ['hue', 'anew'],\n",
       " ['praise', 'days'],\n",
       " ['devised', 'sympathized'],\n",
       " ['lend', 'friend'],\n",
       " ['used', 'abused'],\n",
       " ['need', 'exceed'],\n",
       " ['set', 'debt'],\n",
       " ['report', 'short'],\n",
       " ['show', 'grow'],\n",
       " ['impute', 'mute'],\n",
       " ['dumb', 'tomb'],\n",
       " ['eyes', 'devise'],\n",
       " ['more', 'store'],\n",
       " ['you', 'grew'],\n",
       " ['dwell', 'tell'],\n",
       " ['glory', 'story'],\n",
       " ['writ', 'wit'],\n",
       " ['clear', 'where'],\n",
       " ['curse', 'worse'],\n",
       " ['still', 'quill'],\n",
       " ['compiled', 'filed'],\n",
       " ['words', 'affords'],\n",
       " ['amen', 'pen'],\n",
       " ['true', 'you'],\n",
       " ['more', 'before'],\n",
       " ['respect', 'effect'],\n",
       " ['verse', 'inhearse'],\n",
       " ['you', 'grew'],\n",
       " ['write', 'night'],\n",
       " ['dead', 'astonished'],\n",
       " ['ghost', 'boast'],\n",
       " ['intelligence', 'thence'],\n",
       " ['line', 'mine'],\n",
       " ['possessing', 'releasing'],\n",
       " ['estimate', 'determinate'],\n",
       " ['granting', 'wanting'],\n",
       " ['deserving', 'swerving'],\n",
       " ['knowing', 'growing'],\n",
       " ['mistaking', 'making'],\n",
       " ['flatter', 'matter'],\n",
       " ['light', 'fight'],\n",
       " ['scorn', 'forsworn'],\n",
       " ['acquainted', 'attainted'],\n",
       " ['story', 'glory'],\n",
       " ['too', 'do'],\n",
       " ['thee', 'me'],\n",
       " ['belong', 'wrong'],\n",
       " ['fault', 'halt'],\n",
       " ['offence', 'defence'],\n",
       " ['ill', 'will'],\n",
       " ['change', 'strange'],\n",
       " ['tongue', 'wronk'],\n",
       " ['dwell', 'tell'],\n",
       " ['debate', 'hate'],\n",
       " ['now', 'bow'],\n",
       " ['cross', 'after-loss'],\n",
       " ['sorrow', 'morrow'],\n",
       " ['woe', 'overthrow'],\n",
       " ['last', 'taste'],\n",
       " ['spite', 'might'],\n",
       " ['woe', 'so'],\n",
       " ['skill', 'ill'],\n",
       " ['force', 'horse'],\n",
       " ['pleasure', 'measure'],\n",
       " ['rest', 'best'],\n",
       " ['me', 'be'],\n",
       " ['costs', 'boast'],\n",
       " ['take', 'make'],\n",
       " ['away', 'stay'],\n",
       " ['mine', 'thine'],\n",
       " ['wrongs', 'belongs'],\n",
       " ['end', 'depend'],\n",
       " ['mind', 'find'],\n",
       " ['lie', 'die'],\n",
       " ['blot', 'not'],\n",
       " ['true', 'new'],\n",
       " ['face', 'place'],\n",
       " ['eye', 'history'],\n",
       " ['change', 'strange'],\n",
       " ['decree', 'be'],\n",
       " ['dwell', 'tell'],\n",
       " ['grow', 'show'],\n",
       " ['none', 'stone'],\n",
       " ['show', 'slow'],\n",
       " ['graces', 'faces'],\n",
       " ['expense', 'excellence'],\n",
       " ['sweet', 'meet'],\n",
       " ['die', 'dignity'],\n",
       " ['deeds', 'weeds'],\n",
       " ['shame', 'name'],\n",
       " ['rose', 'enclose'],\n",
       " ['days', 'praise'],\n",
       " ['sport', 'report'],\n",
       " ['got', 'blot'],\n",
       " ['thee', 'see'],\n",
       " ['privilege', 'edge'],\n",
       " ['wantonness', 'less'],\n",
       " ['sport', 'resort'],\n",
       " ['queen', 'seen'],\n",
       " ['esteemed', 'deemed'],\n",
       " ['betray', 'away'],\n",
       " ['translate', 'state'],\n",
       " ['sort', 'report'],\n",
       " ['been', 'seen'],\n",
       " ['year', 'everywhere'],\n",
       " ['time', 'prime'],\n",
       " ['increase', 'decease'],\n",
       " ['me', 'thee'],\n",
       " ['fruit', 'mute'],\n",
       " ['cheer', 'near'],\n",
       " ['spring', 'thing'],\n",
       " ['trim', 'him'],\n",
       " ['smell', 'tell'],\n",
       " ['hue', 'grew'],\n",
       " ['white', 'delight'],\n",
       " ['rose', 'those'],\n",
       " ['away', 'play'],\n",
       " ['long', 'song'],\n",
       " ['might', 'light'],\n",
       " ['redeem', 'esteem'],\n",
       " ['spent', 'argument'],\n",
       " ['survey', 'decay'],\n",
       " ['there', 'everywhere'],\n",
       " ['life', 'knife'],\n",
       " ['amends', 'depends'],\n",
       " ['dyed', 'dignified'],\n",
       " ['say', 'lay'],\n",
       " ['fixed', 'intermixed'],\n",
       " ['dumb', 'tomb'],\n",
       " ['thee', 'be'],\n",
       " ['how', 'now'],\n",
       " ['seeming', 'esteeming'],\n",
       " ['appear', 'where'],\n",
       " ['spring', 'sing'],\n",
       " ['lays', 'days'],\n",
       " ['now', 'bough'],\n",
       " ['night', 'delight'],\n",
       " ['tongue', 'song'],\n",
       " ['forth', 'worth'],\n",
       " ['pride', 'beside'],\n",
       " ['write', 'quite'],\n",
       " ['face', 'disgrace'],\n",
       " ['mend', 'tend'],\n",
       " ['well', 'tell'],\n",
       " ['sit', 'it'],\n",
       " ['old', 'cold'],\n",
       " ['eyed', 'pride'],\n",
       " ['turned', 'burned'],\n",
       " ['seen', 'green'],\n",
       " ['hand', 'stand'],\n",
       " ['perceived', 'deceived'],\n",
       " ['unbred', 'dead'],\n",
       " ['idolatry', 'be'],\n",
       " ['show', 'so'],\n",
       " ['kind', 'confined'],\n",
       " ['excellence', 'difference'],\n",
       " ['argument', 'spent'],\n",
       " ['words', 'affords'],\n",
       " ['alone', 'one'],\n",
       " ['time', 'rhyme'],\n",
       " ['wights', 'knights'],\n",
       " ['best', 'expressed'],\n",
       " ['brow', 'now'],\n",
       " ['prophecies', 'eyes'],\n",
       " ['prefiguring', 'sing'],\n",
       " ['days', 'praise'],\n",
       " ['soul', 'control'],\n",
       " ['come', 'doom'],\n",
       " ['endured', 'assured'],\n",
       " ['presage', 'age'],\n",
       " ['time', 'rhyme'],\n",
       " ['subscribes', 'tribes'],\n",
       " ['monument', 'spent'],\n",
       " ['character', 'register'],\n",
       " ['spirit', 'merit'],\n",
       " ['divine', 'thine'],\n",
       " ['same', 'name'],\n",
       " ['case', 'place'],\n",
       " ['age', 'page'],\n",
       " ['bred', 'dead'],\n",
       " ['heart', 'depart'],\n",
       " ['qualify', 'lie'],\n",
       " ['ranged', 'exchanged'],\n",
       " ['again', 'stain'],\n",
       " ['reigned', 'stained'],\n",
       " ['blood', 'good'],\n",
       " ['call', 'all'],\n",
       " ['there', 'dear'],\n",
       " ['view', 'new'],\n",
       " ['truth', 'youth'],\n",
       " ['above', 'love'],\n",
       " ['end', 'friend'],\n",
       " ['grind', 'confined'],\n",
       " ['best', 'breast'],\n",
       " ['chide', 'provide'],\n",
       " ['deeds', 'breeds'],\n",
       " ['brand', 'hand'],\n",
       " ['subdued', 'renewed'],\n",
       " ['drink', 'think'],\n",
       " ['infection', 'correction'],\n",
       " ['ye', 'me'],\n",
       " ['fill', 'ill'],\n",
       " ['brow', 'allow'],\n",
       " ['strive', 'alive'],\n",
       " ['tongue', 'wrong'],\n",
       " ['care', 'are'],\n",
       " ['sense', 'dispense'],\n",
       " ['bred', 'dead'],\n",
       " ['mind', 'blind'],\n",
       " ['about', 'out'],\n",
       " ['heart', 'part'],\n",
       " ['latch', 'catch'],\n",
       " ['sight', 'night'],\n",
       " ['creature', 'feature'],\n",
       " ['you', 'untrue'],\n",
       " ['you', 'true'],\n",
       " ['flattery', 'alchemy'],\n",
       " ['indigest', 'best'],\n",
       " ['resemble', 'assemble'],\n",
       " ['seeing', 'greeing'],\n",
       " ['up', 'cup'],\n",
       " ['sin', 'begin'],\n",
       " ['lie', 'why'],\n",
       " ['dearer', 'clearer'],\n",
       " ['accidents', 'intents'],\n",
       " ['kings', 'things'],\n",
       " ['tyranny', 'incertainty'],\n",
       " ['best', 'rest'],\n",
       " ['so', 'grow'],\n",
       " ['minds', 'finds'],\n",
       " ['love', 'remove'],\n",
       " ['mark', 'bark'],\n",
       " ['shaken', 'taken'],\n",
       " ['cheeks', 'weeks'],\n",
       " ['come', 'doom'],\n",
       " ['proved', 'loved'],\n",
       " ['all', 'call'],\n",
       " ['repay', 'day'],\n",
       " ['minds', 'winds'],\n",
       " ['right', 'sight'],\n",
       " ['down', 'frown'],\n",
       " ['accumulate', 'hate'],\n",
       " ['prove', 'love'],\n",
       " ['keen', 'unseen'],\n",
       " ['urge', 'purge'],\n",
       " ['sweetness', 'meetness'],\n",
       " ['feeding', 'needing'],\n",
       " ['anticipate', 'state'],\n",
       " ['assured', 'cured'],\n",
       " ['true', 'you'],\n",
       " ['tears', 'fears'],\n",
       " ['within', 'win'],\n",
       " ['committed', 'fitted'],\n",
       " ['never', 'fever'],\n",
       " ['true', 'anew'],\n",
       " ['better', 'greater'],\n",
       " ['content', 'spent'],\n",
       " ['now', 'bow'],\n",
       " ['feel', 'steel'],\n",
       " ['shaken', 'taken'],\n",
       " ['time', 'crime'],\n",
       " ['remembered', 'tendered'],\n",
       " ['hits', 'fits'],\n",
       " ['fee', 'me'],\n",
       " ['esteemed', 'deemed'],\n",
       " ['being', 'seeing'],\n",
       " ['eyes', 'spies'],\n",
       " ['blood', 'good'],\n",
       " ['level', 'bevel'],\n",
       " ['own', 'shown'],\n",
       " ['maintain', 'reign'],\n",
       " ['brain', 'remain'],\n",
       " ['memory', 'eternity'],\n",
       " ['heart', 'part'],\n",
       " ['subsist', 'missed'],\n",
       " ['hold', 'bold'],\n",
       " ['score', 'more'],\n",
       " ['thee', 'me'],\n",
       " ['change', 'strange'],\n",
       " ['might', 'sight'],\n",
       " ['admire', 'desire'],\n",
       " ['old', 'told'],\n",
       " ['defy', 'lie'],\n",
       " ['past', 'haste'],\n",
       " ['be', 'thee'],\n",
       " ['state', 'hate'],\n",
       " ['unfathered', 'gathered'],\n",
       " ['accident', 'discontent'],\n",
       " ['falls', 'calls'],\n",
       " ['heretic', 'politic'],\n",
       " ['hours', 'showers'],\n",
       " ['time', 'crime'],\n",
       " ['canopy', 'eternity'],\n",
       " ['honouring', 'ruining'],\n",
       " ['favour', 'savour'],\n",
       " ['rent', 'spent'],\n",
       " ['heart', 'art'],\n",
       " ['free', 'thee'],\n",
       " ['soul', 'control'],\n",
       " ['fair', 'heir'],\n",
       " ['name', 'shame'],\n",
       " ['power', 'bower'],\n",
       " ['face', 'disgrace'],\n",
       " ['black', 'lack'],\n",
       " ['seem', 'esteem'],\n",
       " ['woe', 'so'],\n",
       " [\"play'st\", \"sway'st\"],\n",
       " ['sounds', 'confounds'],\n",
       " ['leap', 'reap'],\n",
       " ['hand', 'stand'],\n",
       " ['state', 'gait'],\n",
       " ['chips', 'lips'],\n",
       " ['this', 'kiss'],\n",
       " ['shame', 'blame'],\n",
       " ['lust', 'trust'],\n",
       " ['straight', 'bait'],\n",
       " ['had', 'mad'],\n",
       " ['so', 'woe'],\n",
       " ['extreme', 'dream'],\n",
       " ['well', 'hell'],\n",
       " ['sun', 'dun'],\n",
       " ['red', 'head'],\n",
       " ['white', 'delight'],\n",
       " ['cheeks', 'reeks'],\n",
       " ['know', 'go'],\n",
       " ['sound', 'ground'],\n",
       " ['rare', 'compare'],\n",
       " ['art', 'heart'],\n",
       " ['cruel', 'jewel'],\n",
       " ['behold', 'bold'],\n",
       " ['groan', 'alone'],\n",
       " ['swear', 'bear'],\n",
       " ['face', 'place'],\n",
       " ['deeds', 'proceeds'],\n",
       " ['me', 'be'],\n",
       " ['disdain', 'pain'],\n",
       " ['heaven', 'even'],\n",
       " ['east', 'west'],\n",
       " ['face', 'grace'],\n",
       " ['heart', 'part'],\n",
       " ['black', 'lack'],\n",
       " ['groan', 'alone'],\n",
       " ['me', 'be'],\n",
       " ['taken', 'forsaken'],\n",
       " ['engrossed', 'crossed'],\n",
       " ['ward', 'guard'],\n",
       " ['bail', 'gaol'],\n",
       " ['thee', 'me'],\n",
       " ['thine', 'mine'],\n",
       " ['will', 'still'],\n",
       " ['free', 'me'],\n",
       " ['kind', 'bind'],\n",
       " ['take', 'sake'],\n",
       " ['use', 'abuse'],\n",
       " ['me', 'free'],\n",
       " ['will', 'still'],\n",
       " ['over-plus', 'thus'],\n",
       " ['spacious', 'gracious'],\n",
       " ['thine', 'shine'],\n",
       " ['still', 'will'],\n",
       " ['store', 'more'],\n",
       " ['kill', 'will'],\n",
       " ['near', 'there'],\n",
       " ['will', 'fulfil'],\n",
       " ['love', 'prove'],\n",
       " ['one', 'none'],\n",
       " ['untold', 'hold'],\n",
       " ['be', 'thee'],\n",
       " ['still', 'will'],\n",
       " ['eyes', 'lies'],\n",
       " ['see', 'be'],\n",
       " ['looks', 'hooks'],\n",
       " ['ride', 'tied'],\n",
       " ['plot', 'not'],\n",
       " ['place', 'face'],\n",
       " ['erred', 'transferred'],\n",
       " ['truth', 'youth'],\n",
       " ['lies', 'subtleties'],\n",
       " ['young', 'tongue'],\n",
       " ['best', 'suppressed'],\n",
       " ['unjust', 'trust'],\n",
       " ['old', 'told'],\n",
       " ['me', 'be'],\n",
       " ['wrong', 'tongue'],\n",
       " ['heart', 'art'],\n",
       " ['sight', 'might'],\n",
       " ['aside', 'bide'],\n",
       " ['knows', 'foes'],\n",
       " ['enemies', 'injuries'],\n",
       " ['slain', 'pain'],\n",
       " ['press', 'express'],\n",
       " ['disdain', 'pain'],\n",
       " ['were', 'near'],\n",
       " ['so', 'know'],\n",
       " ['mad', 'bad'],\n",
       " ['thee', 'be'],\n",
       " ['belied', 'wide'],\n",
       " ['eyes', 'despise'],\n",
       " ['note', 'dote'],\n",
       " ['delighted', 'invited'],\n",
       " ['prone', 'alone'],\n",
       " ['can', 'man'],\n",
       " ['thee', 'be'],\n",
       " ['gain', 'pain'],\n",
       " ['hate', 'state'],\n",
       " ['loving', 'reproving'],\n",
       " ['thine', 'mine'],\n",
       " ['ornaments', 'rents'],\n",
       " ['those', 'grows'],\n",
       " ['thee', 'be'],\n",
       " ['hide', 'denied'],\n",
       " ['catch', 'dispatch'],\n",
       " ['away', 'stay'],\n",
       " ['chase', 'face'],\n",
       " ['bent', 'discontent'],\n",
       " ['thee', 'me'],\n",
       " ['behind', 'kind'],\n",
       " ['will', 'still'],\n",
       " ['despair', 'fair'],\n",
       " ['still', 'ill'],\n",
       " ['evil', 'devil'],\n",
       " ['side', 'pride'],\n",
       " ['fiend', 'friend'],\n",
       " ['tell', 'hell'],\n",
       " ['doubt', 'out'],\n",
       " ['make', 'sake'],\n",
       " ['hate', 'state'],\n",
       " ['come', 'doom'],\n",
       " ['sweet', 'greet'],\n",
       " ['end', 'fiend'],\n",
       " ['day', 'away'],\n",
       " ...]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyming_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When this therein coral grace thee knife your, \n",
      " Golden stay doth left relief tempting and: \n",
      " Are earth what serving well ' , . when but to and: \n",
      " Sin too but comment , guess the offender's, \n",
      " Needs or tend do night , thy asleep enjoys, \n",
      " , you perceived but a love thousand . men's there: \n",
      " Which delves as then no seen into which this: \n",
      " Mourning much blamed defect brow thou and on, \n",
      " Others to if those love all to age to, \n",
      " Then , though love , be benefit he least did: \n",
      " Twain of how spurring is spread were that in, \n",
      " Check time , it due doth so world , and it hear, \n",
      " , i'll ' , peep , seeing dulness to thou from can, \n",
      " Self , thy see to truly giving ) o had, \n",
      " \n",
      "[0, 0, 1, 0, 1, 0, 1, 3]\n",
      "[3, 2, 1, 3, 2, 1, 0]\n",
      "[3, 2, 1, 3, 2, 2, 1, 1, 0, 1, 1, 0]\n",
      "[2, 1, 3, 2, 1, 3, 2, 1]\n",
      "[2, 3, 2, 3, 2, 1, 3, 2, 1]\n",
      "[1, 3, 2, 1, 3, 2, 1, 1, 0, 1]\n",
      "[2, 1, 0, 1, 3, 2, 1, 0, 1, 1]\n",
      "[1, 3, 2, 2, 2, 1, 0, 1]\n",
      "[3, 2, 1, 3, 2, 1, 3, 2, 1]\n",
      "[0, 1, 3, 2, 1, 3, 2, 1, 0, 1, 1]\n",
      "[2, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "[0, 0, 1, 0, 0, 1, 3, 2, 1, 0, 1, 1]\n",
      "[1, 3, 2, 1, 0, 1, 3, 2, 1, 1, 3, 2]\n",
      "[2, 1, 3, 2, 2, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnet , h_states = Shakespeare_naive(hmm_shakespeare_4)\n",
    "print(sonnet)\n",
    "[print(h_states[i]) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku , haiku_states = Shakespeare_haiku(hmm_shakespeare_4)\n",
    "print(haiku)\n",
    "[print(haiku_states[i]) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks his , so pays not equal far winged\n"
     ]
    }
   ],
   "source": [
    "sonnets, states = hmm_shakespeare_4.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,\"winged\")\n",
    "print(' '.join(sonnets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shakespeare_rhyme(hmm):\n",
    "    sonnet = ''\n",
    "    for i in np.arange(3):\n",
    "        seeds1 = random.choice(rhyming_words)\n",
    "        seeds2 = random.choice(rhyming_words)\n",
    "        seed1 = seeds1[0]\n",
    "        seed2 = seeds2[0]\n",
    "        seed3 = seeds1[1]\n",
    "        seed4 = seeds2[1]\n",
    "        sonnet += \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seed1)[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n'\n",
    "        sonnet += \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seed2)[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n'\n",
    "        sonnet += \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seed3)[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n'\n",
    "        sonnet += \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seed4)[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n'\n",
    "        sonnet += \"\\n\"\n",
    "    seeds3 = random.choice(rhyming_words)\n",
    "    sonnet += \" \" + \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seeds3[0])[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n '\n",
    "    sonnet += \" \".join(hmm.rhyme_line(syllables_notend_dict,syllables_end_dict,numbertoword_dict,wordtonumber_dict,seeds3[1])[0]).capitalize()+np.random.choice(punctuation, p=punctuation_probs) + '\\n '\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic to still my added unrest kings,\n",
      "Amis thou no harsh on an pleasure worth:\n",
      "So now so night entombed , and some things.\n",
      "Faults yet with remember in thou him , forth,\n",
      "\n",
      "Nor seen of yet he but never which say:\n",
      "Might but look garments thy seeing . distilled,\n",
      "There shame more dear argument when up pay,\n",
      "Doth art on thy strive , time's bankrupt self-killed,\n",
      "\n",
      "And withering have from quality costs \n",
      "Even to extern name . or audit gain,\n",
      "Anew have pass roses from the sweet boast,\n",
      "Self from make woman pen mayst doom dost main,\n",
      "\n",
      " The beauty's need but i draw this youth shore,\n",
      " World i so it more of than this eyes store,\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(Shakespeare_rhyme(hmm_shakespeare_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677768689299\n",
      "0.677768689299\n",
      "0.677768507937\n",
      "0.677768507937\n",
      "0.677768507746\n",
      "0.677768507746\n",
      "0.677768065212\n",
      "0.677768065212\n",
      "0.677767869573\n",
      "0.677767869573\n",
      "0.677767869573\n",
      "0.677767869573\n",
      "0.160872687937\n",
      "0.0155489052722\n",
      "0.0155489052677\n",
      "-0.29464473592\n"
     ]
    }
   ],
   "source": [
    "state = 0\n",
    "next_state = 0\n",
    "rand_var = random.uniform(0, np.array(hmm_shakespeare_4.A)[:,state].sum())\n",
    "print(rand_var)\n",
    "while rand_var > 0:\n",
    "    rand_var -= hmm_shakespeare_4.A[next_state][state]\n",
    "    print(rand_var)\n",
    "    next_state += 1\n",
    "#np.array(hmm_shakespeare_4.A)[next_state,state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
